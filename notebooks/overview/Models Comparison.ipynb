{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a1522c",
   "metadata": {},
   "source": [
    "### EVALUATING THE MODELS\n",
    "\n",
    "* ### CNN\n",
    "* ### XGB\n",
    "* ### NN\n",
    "* ### XGB+NN hard vote\n",
    "* ### XGB+NN soft vote\n",
    "\n",
    "\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58476664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, LabelEncoder, StandardScaler, minmax_scale\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from librosa import cqt\n",
    "from librosa.feature import *\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import datetime\n",
    "import ffmpeg\n",
    "import os\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6fd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler \n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, SCORERS,  ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import xgboost\n",
    "import joblib\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.layers import BatchNormalization\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d7cbe",
   "metadata": {},
   "source": [
    "### Loading and splitting Features for XGB and NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad97044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27870, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../../features/features_new_14genres_5sec.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c552ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 28)\n"
     ]
    }
   ],
   "source": [
    "drop_features=['genre','file_name']\n",
    "\n",
    "\n",
    "X = df.drop(drop_features,axis=1)\n",
    "y = df['genre']\n",
    "\n",
    "# Train/test split for XGB and NN\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(np.array(X_train, dtype = float))\n",
    "X_test_scaled = scaler.transform(np.array(X_test, dtype = float))\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_test_num = encoder.fit_transform(y_test)\n",
    "y_train_num = encoder.transform(y_train)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92dba7",
   "metadata": {},
   "source": [
    "### Loading image data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ac2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../../data_images/set_2x2-8-1-1_5sec.pkl\"\n",
    "with open(file_name, \"rb\") as f:\n",
    "      saved_images=pickle.load(f)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14490b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = saved_images[0]\n",
    "test_images, test_labels = saved_images[1]\n",
    "val_images, val_labels = saved_images[2]\n",
    "\n",
    "# Reshaping:\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "train_y=np.array([np.argmax(i) for i in train_labels]).reshape(train_images.shape[0], -1)\n",
    "test_y=np.array([np.argmax(i) for i in test_labels]).reshape(test_images.shape[0], -1)\n",
    "val_y=np.array([np.argmax(i) for i in val_labels]).reshape(val_images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21170bd4",
   "metadata": {},
   "source": [
    "###  Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2bab23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelNN = load_model('../../models/NN_model_5sec_14genres.h5')\n",
    "modelCNN = load_model('../../models/CNN_best_model_5sec(94).h5')\n",
    "\n",
    "modelXGB = XGBClassifier()\n",
    "modelXGB.load_model(\"../../models/XGB_model.json\")\n",
    "#modelXGB.save_model(\"../../models/XGB_model.bin\")\n",
    "    \n",
    "with open('../../models/NN_transformers_6sec_14genres_new.joblib', 'rb') as f:\n",
    "    encoder,scaler = joblib.load(f)\n",
    "    \n",
    "genres=encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96effa",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## Combining Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16e617",
   "metadata": {},
   "source": [
    "### XGB and NN Soft Vote predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a419cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOFT VOTE\n",
    "\n",
    "CNN_prob = modelCNN.predict(test_images)\n",
    "NN_prob=modelNN.predict(X_test_scaled)\n",
    "XGB_prob=modelXGB.predict_proba(X_test)\n",
    "\n",
    "sum_prob=(XGB_prob+NN_prob)/2\n",
    "sum_pred=np.argmax(sum_prob, axis=1)\n",
    "\n",
    "CNN_pred=np.argmax(CNN_prob, axis=1)\n",
    "NN_pred=np.argmax(NN_prob, axis=1)\n",
    "XGB_pred=modelXGB.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e417d",
   "metadata": {},
   "source": [
    "### XGB and NN Hard Vote predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9459098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on comparing the precision scores when predicted classes are different\n",
    "\n",
    "NN_prec=precision_score(y_test_num, NN_pred, average=None)\n",
    "XGB_prec=precision_score(y_test_num, XGB_pred, average=None)\n",
    "\n",
    "NN_prec_dic={key:value for key, value in  enumerate(NN_prec) }\n",
    "XGB_prec_dic={key:value for key, value in  enumerate(XGB_prec) }\n",
    "\n",
    "NN_and_XGB_hard_vote=[]\n",
    "for i in range(len(NN_pred)):\n",
    "    if NN_pred[i] == XGB_pred [i]:\n",
    "        NN_and_XGB_hard_vote.append(NN_pred[i])\n",
    "    else:\n",
    "        if NN_prec_dic[NN_pred[i]] >= XGB_prec_dic[XGB_pred[i]]:\n",
    "            NN_and_XGB_hard_vote.append(NN_pred[i])\n",
    "        else:\n",
    "            NN_and_XGB_hard_vote.append(XGB_pred[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b81fb",
   "metadata": {},
   "source": [
    "### Comparing Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c72f1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Testing Accuracy:  0.9420807957649231\n",
      "XGB Testing Accuracy:  0.9467168998923574\n",
      "NN Testing Accuracy:  0.9655543565750122\n",
      "NN+XGB hard vote accuracy:  0.9635809113742375\n",
      "NN+XGB soft vote accuracy:  0.9702188733405095\n"
     ]
    }
   ],
   "source": [
    "CNN_score = modelCNN.evaluate(test_images, test_y, verbose=0)\n",
    "NN_score = modelNN.evaluate(X_test_scaled, y_test_num, verbose=0)\n",
    "XGB_score=modelXGB.score(X_test, y_test_num )\n",
    "NN_and_XGB_soft_score=accuracy_score(y_test_num, sum_pred)\n",
    "NN_and_XGB_hard_score=accuracy_score(y_test_num, NN_and_XGB_hard_vote)\n",
    "\n",
    "print(\"CNN Testing Accuracy: \", CNN_score[1])\n",
    "print(\"XGB Testing Accuracy: \", XGB_score)\n",
    "print(\"NN Testing Accuracy: \", NN_score[1])\n",
    "print(\"NN+XGB hard vote accuracy: \", NN_and_XGB_hard_score)\n",
    "print(\"NN+XGB soft vote accuracy: \", NN_and_XGB_soft_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c37d9a6",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "* #### NN+XGB soft vote ensemble works the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda63a55",
   "metadata": {},
   "source": [
    "In the classifier I also combine soft vote of CNN+NN+XGB , however additional testings are required to get the accuracy score ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119a776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
